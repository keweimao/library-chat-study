{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook serves as documentation for the reproducibility study of the library-chat-study in preparation for IMLS grant proposal.\n",
    "\n",
    "\n",
    "P1 Steps:\n",
    "1. Make your own copy of the library-chat-study either through Git or Collaboratory, etc.\n",
    "2. Run the P1 utility functions and comment out the importer for it or make sure you import correctly, as they are all definitions of the same functions.\n",
    "3. Download nltk wordnet via !pip install nltk if in collab, or using pip install nltk if not in collab.\n",
    "4. Insert the csv data needed, and copy its path for input into the function.\n",
    "5. Copy path for stop_words.txt for its input into the function.\n",
    "6. Run the function, put path for csv and txt\n",
    "7. Wait, as it outputs files.\n",
    "\n",
    "\n",
    "Gaps: \n",
    "1. Slight tweaking of the file was needed to make things work for step 1, which is standard.\n",
    "2. We can improve by perhaps adding different ways of preprocessing as per the literature review, as it's known that LDA can be tempered by different preprocessing.\n",
    "\n",
    "\n",
    "P2 Steps:\n",
    "1. Make sure all libraries are loaded\n",
    "2. Run the p2 utility functions and comment out the importer for it or make sure you import correctly, as they are all definitions of the same functions.\n",
    "3. Run the function, put path for wholeChatsFile.txt into the step 1, because it used OS for path of files.\n",
    "4. Put number of topics (can be found using topic coherence, look at the curve and imput into step 2)\n",
    "5. Put number of words per topics (5-10 is a good number)\n",
    "6. Wait, as it's performing PyMallet LDA and might take a couple of minutes which is standard with these sorts of algorithms!\n",
    "\n",
    "\n",
    "Errors:\n",
    "\n",
    "\n",
    "Original code:  tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=max_features, stop_words='english')                                        \n",
    "\n",
    "\n",
    "Fix:            tf_vectorizer = CountVectorizer(max_features=max_features, stop_words='english') - going back to default values for max and min because raised value error\n",
    "\n",
    "\n",
    "Result:         Did not work because the max_df and min_df need to be tweaked in such a way that there is a NaN or inf in the matrix being inverted within the code.\n",
    "\n",
    "\n",
    "Gaps:\n",
    "1. Since we are using PyMallet, perhaps we can explore other implementations of LDA if needed.\n",
    "2. We can try to use other methods of topic modeling that are not prone to issues on small corpora.\n",
    "3. Perhaps we should explore methods that take less time (if that is an issue).\n",
    "4. Because pLSA was found to be one of the most efficient methods of topic modeling in the original paper, we might try to use Pachinko Allocation Model (PAM) in MALLET, another technique which improves LDA on greater expressibility.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43794f9dbf35c8071020a62fff6bd77ce265685b8e1bb5f42a73b85f9efdf7ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
