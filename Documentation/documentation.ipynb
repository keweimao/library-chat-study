{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook serves as documentation for the reproducibility study of the library-chat-study in preparation for IMLS grant proposal.\n",
    "\n",
    "ALl of the Reproducibility Techniques have been implemented in \"TestScripts.ipynb.\"\n",
    "\n",
    "P1 Steps:\n",
    "1. Make your own copy of the library-chat-study either through Git or Collaboratory, etc.\n",
    "2. Run the P1 utility functions and comment out the importer for it or make sure you import correctly, as they are all definitions of the same functions.\n",
    "3. Download nltk wordnet via !pip install nltk if in collab, or using pip install nltk if not in collab.\n",
    "4. Insert the csv data needed, and copy its path for input into the function.\n",
    "5. Copy path for stop_words.txt for its input into the function.\n",
    "6. Run the function, put path for csv and txt\n",
    "7. Wait, as it outputs files.\n",
    "\n",
    "\n",
    "Gaps: \n",
    "1. Slight tweaking of the file was needed to make things work for step 1, which is standard.\n",
    "2. We can improve by perhaps adding different ways of preprocessing as per the literature review, as it's known that LDA can be tempered by different preprocessing.\n",
    "3. Since downstream issues occurred with respect to preprocessing, especially after changing the corpus structure, we can improve by adding more preprocessing techniques.\n",
    "\n",
    "\n",
    "P2 Steps:\n",
    "1. Make sure all libraries are loaded\n",
    "2. Run the p2 utility functions and comment out the importer for it or make sure you import correctly, as they are all definitions of the same functions.\n",
    "3. Run the function, put path for wholeChatsFile.txt into the step 1, because it used OS for path of files.\n",
    "4. Put number of topics (can be found using topic coherence, look at the curve and imput into step 2)\n",
    "5. Put number of words per topics (5-10 is a good number)\n",
    "6. Wait, as it's performing PyMallet LDA and might take a couple of minutes which is standard with these sorts of algorithms!\n",
    "\n",
    "\n",
    "Errors:\n",
    "\n",
    "\n",
    "Original code:  tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=max_features, stop_words='english')                                        \n",
    "\n",
    "\n",
    "Fix:            tf_vectorizer = CountVectorizer(max_features=max_features, stop_words='english') - going back to default values for max and min because raised value error\n",
    "\n",
    "\n",
    "Result:         Did not work because the max_df and min_df need to be tweaked in such a way that there is a NaN or inf in the matrix being inverted within the code.\n",
    "\n",
    "\n",
    "Gaps:\n",
    "1. Since we are using PyMallet, perhaps we can explore other implementations of LDA if needed.\n",
    "2. Perhaps we should explore methods that take less time (if that is an issue).\n",
    "3. Because pLSA was found to be one of the most efficient methods of topic modeling in the original paper, we might try to use Pachinko Allocation Model (PAM) in MALLET, another technique which improves LDA on greater expressibility.\n",
    "\n",
    "\n",
    "P3 Steps:\n",
    "1. Make sure all libraries are loaded\n",
    "2. Make sure you previously ran the P1 and P2 steps, then proceed to run P3 utility functions.\n",
    "3. Make sure you fix the issue with GuidedLDA, using the correct GitHub link found at https://github.com/dex314/GuidedLDA_WorkAround.\n",
    "4. Make sure anchors.txt is created, as that will be necessary for running the function.\n",
    "5. Run the function, inputting the wholeChatsFile.txt path, the anchors.txt path, the number of topics, and the number of words per topic.\n",
    "\n",
    "\n",
    "Errors:\n",
    "\n",
    "\n",
    "We find that there was an all zero column in the document-term matrix for GuidedLDA.\n",
    "\n",
    "\n",
    "This might have necessitated from issues with preprocessing, or with the fact that GuidedLDA is now prone to issues on Windows OS, including Google Collaboratory.\n",
    "\n",
    "\n",
    "Gaps:\n",
    "1. The GuidedLDA website notes that if we are working with a larger corpus, we may want to use more sophisticated methods of topic modeling such as those provided in hca and MALLET.\n",
    "2. Preprocessing needs to be updated and refined to better handle the issues with downstream issues, such as errors with LDA. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43794f9dbf35c8071020a62fff6bd77ce265685b8e1bb5f42a73b85f9efdf7ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
